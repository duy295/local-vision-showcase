#!/usr/bin/env python3
"""
ðŸš€ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG LOSS.PY Má»šI - QUICK REFERENCE

Lá»‹ch sá»­ thay Ä‘á»•i:
âœ… ThÃªm tá»± Ä‘á»™ng phÃ¡t hiá»‡n dataset (CIFAR100, CUB200, ImageNetR)
âœ… ThÃªm loading json_global vÃ  json_final embeddings tá»« file
âœ… ThÃªm caching mechanism Ä‘á»ƒ tá»‘i Æ°u tá»‘c Ä‘á»™
"""

import torch
from backbone.loss import StructureAwareClipLoss

# âš™ï¸ STEP 1: Chuáº©n bá»‹ danh sÃ¡ch class names
# VÃ­ dá»¥ cho CIFAR-100 (100 classes)
cifar100_classes = [
    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver',
    'bed', 'bee', 'beetle', 'bicycle', 'bottle',
    # ... (tá»•ng 100 classes)
]

# âš™ï¸ STEP 2: Khá»Ÿi táº¡o Loss Function
loss_fn = StructureAwareClipLoss(
    output_json_path=r'c:\Users\FPT SHOP\CODING PROBLEM\LLM via FSCIL\output_json',
    dataset_name='cifar100',              # ðŸŽ¯ Tá»± Ä‘á»™ng detect: CIFAR100
    label_to_classname=cifar100_classes,  # List hoáº·c Dict mapping
    alpha=0.05,    # Threshold cho khÃ¡c class
    alpha_soft=0.2, # Threshold má»m
    beta=0.9,      # Min boundary
    device='cuda'  # GPU hoáº·c 'cpu'
)

# ðŸ“Š Output:
# ðŸ” Äang sá»­ dá»¥ng dataset: CIFAR100
# âœ“ ÄÃ£ tÃ¬m tháº¥y thÆ° má»¥c: c:\Users\FPT SHOP\CODING PROBLEM\LLM via FSCIL\output_json\cifar100
# âœ“ Sá»‘ lÆ°á»£ng class: 100

# âš™ï¸ STEP 3: Chuáº©n bá»‹ dá»¯ liá»‡u
batch_size = 8
feat_dim = 512

fuzzy_scores = torch.randn(batch_size, device='cuda')  # [B] Output RelationNet
feat1 = torch.randn(batch_size, feat_dim, device='cuda')  # [B, D]
feat2 = torch.randn(batch_size, feat_dim, device='cuda')  # [B, D]
label1 = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7], device='cuda')  # Label áº£nh 1
label2 = torch.tensor([0, 1, 2, 8, 9, 10, 11, 12], device='cuda')  # Label áº£nh 2

# âš™ï¸ STEP 4: TÃ­nh Loss
loss = loss_fn(fuzzy_scores, feat1, feat2, label1, label2)
print(f"Loss value: {loss.item():.4f}")

# ============================================================
# ðŸ“‚ CÃCH 2: Cho CUB-200
# ============================================================
cub200_classes = [
    'acadian_flycatcher', 'american_crow', 'american_goldfinch',
    # ... (200 classes)
]

loss_fn_cub = StructureAwareClipLoss(
    output_json_path=r'c:\Users\FPT SHOP\CODING PROBLEM\LLM via FSCIL\output_json',
    dataset_name='CUB200',              # ðŸŽ¯ Tá»± Ä‘á»™ng detect: CUB200
    label_to_classname=cub200_classes,
    device='cuda'
)

# ============================================================
# ðŸ“‚ CÃCH 3: DÃ¹ng Dict thay vÃ¬ List
# ============================================================
label_mapping = {
    0: 'apple',
    1: 'aquarium_fish',
    2: 'baby',
    # ... (mapping cho táº¥t cáº£ labels)
}

loss_fn_dict = StructureAwareClipLoss(
    output_json_path=r'c:\Users\FPT SHOP\CODING PROBLEM\LLM via FSCIL\output_json',
    dataset_name='cifar100',
    label_to_classname=label_mapping,  # âœ… CÅ©ng hoáº¡t Ä‘á»™ng tá»‘t
    device='cuda'
)

# ============================================================
# ðŸ”§ TÃNH NÄ‚NG: Caching Embeddings
# ============================================================
# ðŸ’¡ Tá»± Ä‘á»™ng cache embeddings -> trÃ¡nh Ä‘á»c file láº·p láº¡i
# Cache key: (label_id, embedding_type='final'/'global')
# 
# Láº§n Ä‘áº§u load label 0 final: Ä‘á»c tá»« file + cache
# Láº§n thá»© 2 load label 0 final: láº¥y tá»« cache (nhanh hÆ¡n)

# ============================================================
# ðŸŽ¯ DATASET DETECTION
# ============================================================
# Supported datasets:
# - 'cifar100' hoáº·c 'CIFAR100' -> output_json/cifar100/
# - 'cub200' hoáº·c 'CUB200'     -> output_json/CUB200/
# - 'imagenetr' hoáº·c 'ImageNetR' -> output_json/ImageNetR/

# âœ… Case-insensitive, tá»± Ä‘á»™ng convert thÃ nh Ä‘Ãºng folder name

# ============================================================
# ðŸ“‹ STRUCTURE JSON FILES
# ============================================================
# Má»—i dataset folder cÃ³ cáº¥u trÃºc:
# 
# output_json/
# â”œâ”€â”€ cifar100/
# â”‚   â”œâ”€â”€ apple_final.json       <- [float, float, ...]
# â”‚   â”œâ”€â”€ apple_global.json      <- [float, float, ...]
# â”‚   â”œâ”€â”€ aquarium_fish_final.json
# â”‚   â”œâ”€â”€ aquarium_fish_global.json
# â”‚   â””â”€â”€ ...
# â”œâ”€â”€ CUB200/
# â”‚   â”œâ”€â”€ acadian_flycatcher_final.json
# â”‚   â”œâ”€â”€ acadian_flycatcher_global.json
# â”‚   â””â”€â”€ ...
# â””â”€â”€ ImageNetR/

# ============================================================
# âš ï¸ ERROR HANDLING
# ============================================================
# Dataset khÃ´ng há»£p lá»‡? -> ValueError
# ThÆ° má»¥c khÃ´ng tá»“n táº¡i? -> FileNotFoundError
# JSON file missing? -> FileNotFoundError
# label_to_classname is None? -> ValueError

# Example error messages:
# âŒ ValueError: Dataset 'invalid' khÃ´ng há»£p lá»‡. Chá»n: ['cifar100', 'cub200', 'imagenetr']
# âŒ FileNotFoundError: KhÃ´ng tÃ¬m tháº¥y file: output_json/cifar100/apple_final.json

# ============================================================
# ðŸŽ“ TRAINING LOOP EXAMPLE
# ============================================================
def train_epoch(model, relation_net, loss_fn, dataloader, optimizer, device='cuda'):
    total_loss = 0
    
    for batch_idx, (
        query_img, support_img, query_label, support_label
    ) in enumerate(dataloader):
        # Move to device
        query_img = query_img.to(device)
        support_img = support_img.to(device)
        query_label = query_label.to(device)
        support_label = support_label.to(device)
        
        # Forward pass
        query_feat = model(query_img)  # [B, 512]
        support_feat = model(support_img)  # [B, 512]
        
        fuzzy_scores = relation_net(query_feat, support_feat)  # [B]
        
        # Compute loss
        loss = loss_fn(
            fuzzy_scores,
            query_feat,
            support_feat,
            query_label,
            support_label
        )
        
        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        if batch_idx % 10 == 0:
            print(f"Batch {batch_idx}: Loss = {loss.item():.4f}")
    
    avg_loss = total_loss / len(dataloader)
    print(f"Epoch Average Loss: {avg_loss:.4f}")
    return avg_loss

# ============================================================
# ðŸ’¡ TIPS & TRICKS
# ============================================================
# 1ï¸âƒ£ Embeddings Ä‘Æ°á»£c normalize tá»± Ä‘á»™ng
# 2ï¸âƒ£ Caching hoáº¡t Ä‘á»™ng across batches - cÃ ng lÃ¢u cache cÃ ng tá»‘t
# 3ï¸âƒ£ label_to_classname lÃ  báº¯t buá»™c
# 4ï¸âƒ£ Há»— trá»£ cáº£ List [class1, class2, ...] hoáº·c Dict {0: class1, ...}
# 5ï¸âƒ£ Device parameter cho GPU/CPU acceleration

print("âœ… Loss.py Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t thÃ nh cÃ´ng!")
print("ðŸŽ¯ Sá»­ dá»¥ng hÃ m StructureAwareClipLoss() vá»›i 3 tham sá»‘ chÃ­nh:")
print("   - output_json_path: ÄÆ°á»ng dáº«n thÆ° má»¥c output_json")
print("   - dataset_name: TÃªn dataset (cifar100/cub200/imagenetr)")
print("   - label_to_classname: List hoáº·c Dict Ã¡nh xáº¡ label -> class name")
