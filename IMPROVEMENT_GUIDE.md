# ğŸ¯ CÃ¡c Cáº£i Tiáº¿n Cáº§n Thiáº¿t Cho Model Comparison

## ğŸ“‹ TÃ³m Táº¯t Hiá»‡n Tráº¡ng

Model hiá»‡n táº¡i cá»§a báº¡n **CÃ“ Äá»¦** kháº£ nÄƒng so sÃ¡nh 2 áº£nh nhÆ°ng cáº§n tá»‘i Æ°u:
- âœ… BilinearRelationNet: ÄÃ£ cÃ³ hÃ m so sÃ¡nh  
- âœ… HybridResNetBackbone: Extract features tá»‘t
- âš ï¸ NhÆ°ng: Thiáº¿u pipeline inference, khÃ´ng táº­n dá»¥ng CLIP embeddings Ä‘áº§y Ä‘á»§

---

## ğŸ”§ 5 Cáº£i Tiáº¿n ChÃ­nh

### 1. **TÃ¡ch Inference from Training** â­ (PRIORITY 1)
**Váº¥n Ä‘á»**: main.py quÃ¡ phá»©c táº¡p cho training, khÃ´ng tiá»‡n dÃ¹ng cho inference

**Giáº£i phÃ¡p**: TÃ´i Ä‘Ã£ táº¡o `inference.py` vá»›i:
```python
comparator = ImageSimilarityComparator(
    backbone_path='weights/backbone_full.pth',
    relation_path='weights/relation_full.pth'
)

score_dict = comparator.compare_images('img1.jpg', 'img2.jpg')
# Output: {'visual_score': 0.75, 'concept_score': 0.82, 'final_score': 0.77}
```

**Lá»£i Ã­ch**: 
- Minimize, clean code cho inference
- Dá»… integrate vÃ o cÃ¡c app khÃ¡c
- Load model 1 láº§n, compare N láº§n

---

### 2. **Tá»‘i Æ¯u Feature Normalization** (PRIORITY 1)
**Váº¥n Ä‘á»**: Features khÃ´ng normalize â†’ giáº£m accuracy

**Giáº£i phÃ¡p** (Ä‘Ã£ implement trong inference.py):
```python
# Normalize features Ä‘á»ƒ so sÃ¡nh cÃ´ng báº±ng
features = backbone(image)  # [1, 512]
features = F.normalize(features, p=2, dim=1)  # L2 norm

# Thay vÃ¬:
similarity = relation_net(feat1, feat2)
# CÃ³ thá»ƒ thÃªm:
cosine_sim = F.cosine_similarity(feat1, feat2)  # 0 = khÃ¡c, 1 = giá»‘ng há»‡t
```

---

### 3. **Káº¿t Há»£p CLIP Concept Embeddings** (PRIORITY 2)
**Váº¥n Ä‘á»**: Chá»‰ dÃ¹ng visual similarity â†’ khÃ´ng capture semantic meaning

**Giáº£i phÃ¡p**:
```python
# final_score = visual_score + concept_score (weighted)
visual_sim = relu_net(feat1, feat2)      # 0-1
concept_sim = compute_concept_similarity(feat1, feat2)  # 0-1

# Combine weights cÃ³ thá»ƒ tune:
final_score = 0.7 * visual_sim + 0.3 * concept_sim

# VÃ­ dá»¥:
# Image1 (chim A) vs Image2 (chim A): visual=0.8, concept=0.95 â†’ final=0.85
# Image1 (chim A) vs Image3 (chim B): visual=0.6, concept=0.3 â†’ final=0.51
```

**Implement** (Ä‘Ã£ cÃ³ trong inference.py):
```python
def _compute_concept_similarity(self, feat1, feat2):
    # So sÃ¡nh features vá»›i táº¥t cáº£ concept embeddings
    # Return: max similarity score
```

---

### 4. **ThÃªm Batch Comparison & Ranking** (PRIORITY 2)
**Váº¥n Ä‘á»**: Chá»‰ so sÃ¡nh 1 cáº·p áº£nh, khÃ´ng cÃ³ ranking

**Giáº£i phÃ¡p** - ThÃªm vÃ o inference.py:
```python
def find_similar_images(self, query_image, image_list, top_k=10):
    """
    TÃ¬m K áº£nh giá»‘ng query_image nháº¥t tá»« danh sÃ¡ch
    """
    scores = []
    for img_path in image_list:
        result = self.compare_images(query_image, img_path, verbose=False)
        scores.append((img_path, result['final_score']))
    
    # Sort vÃ  return top_k
    scores.sort(key=lambda x: x[1], reverse=True)
    return scores[:top_k]
```

**á»¨ng dá»¥ng**: 
- Search cÃ¡c áº£nh chim tÆ°Æ¡ng tá»±
- Recommendation systems
- Duplicate detection

---

### 5. **Cáº£i Tiáº¿n Main Training** (PRIORITY 3)
**Nhá»¯ng Ä‘iá»u cáº§n sá»­a trong main.py**:

| Má»¥c | Hiá»‡n táº¡i | Cáº§n cáº£i | TÃ¡c dá»¥ng |
|-----|---------|--------|---------|
| **Inference mode** | âŒ KhÃ´ng cÃ³ | âœ… ThÃªm `--mode inference` | DÃ¹ng Ä‘á»ƒ test nhanh |
| **Save best model** | âŒ Save háº¿t | âœ… Save only best | Tiáº¿t kiá»‡m disk |
| **Feature export** | âŒ KhÃ´ng cÃ³ | âœ… Export features to NPZ | DÃ¹ng cho retrieval |
| **Concept weighting** | âŒ Cá»‘ Ä‘á»‹nh | âœ… Tunable weights | Optimize performance |
| **Validation split** | âŒ KhÃ´ng cÃ³ | âœ… ThÃªm validation set | Monitor overfitting |

---

## ğŸ“Š Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Image 1 & 2     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HybridResNetBackbone                    â”‚
â”‚ - Global feature extraction             â”‚
â”‚ - Patch-based features                  â”‚
â”‚ Output: [B, 512] normalized features    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
         â”‚                              â”‚
         â–¼                              â–¼
    feat1 [512]                    feat2 [512]
         â”‚                              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                           â”‚
          â–¼                           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ BilinearRelationNet      â”‚ Concept Similarityâ”‚
    â”‚ visual_score: 0.75       â”‚ from CLIP embeddings
    â”‚                          â”‚ concept_score: 0.82
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                           â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Weighted Combination                 â”‚
    â”‚ final = 0.7*visual + 0.3*concept     â”‚
    â”‚ RESULT: 0.77 âœ…                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### Option 1: Direct Python (Recommended)
```python
from inference import ImageSimilarityComparator

comparator = ImageSimilarityComparator(
    backbone_path='weights/backbone_full.pth',
    relation_path='weights/relation_full.pth',
    concept_embeddings_dir='output_json/CUB200'
)

result = comparator.compare_images('bird1.jpg', 'bird2.jpg')
print(f"Similarity: {result['final_score']:.2%}")
```

### Option 2: Command Line
```bash
python inference.py img1.jpg img2.jpg \
    --backbone weights/backbone_full.pth \
    --relation weights/relation_full.pth \
    --concept-dir output_json/CUB200
```

---

## ğŸ“ˆ Performance Tips

1. **Batch processing** giÃºp tÄƒng tá»‘c Ä‘á»™:
```python
# Slow: Compare 1000 pairs sequentially
# Fast: Extract all features once â†’ compare all pairs
```

2. **Cache embeddings**:
```python
# Load concept embeddings 1 láº§n, reuse many times
# Tiáº¿t kiá»‡m ~50% time
```

3. **Use GPU** cho feature extraction:
```python
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model.to(device)
```

---

## âœ… Checklist Cáº£i Tiáº¿n

- [x] Táº¡o inference.py (ready to use)
- [ ] Test inference.py vá»›i 2 áº£nh test
- [ ] Adjust weights (visual vs concept) dá»±a trÃªn káº¿t quáº£
- [ ] ThÃªm batch comparison function
- [ ] Add feature export for retrieval
- [ ] Create web API wrapper (FastAPI)
- [ ] Deploy model as service

---

## ğŸ’¡ Recommended Next Steps

1. **Test inference.py** ngay vá»›i áº£nh test:
   ```bash
   python inference.py test_img1.jpg test_img2.jpg
   ```

2. **Tá»‘i Æ°u weights** (0.7/0.3):
   - Test vá»›i 100 áº£nh pairs
   - Find best visual/concept ratio
   
3. **Add evaluation metrics**:
   - Recall@K (top-K retrieval)
   - mAP (mean Average Precision)
   - Precision/Recall curves

4. **Scale up**:
   - Batch processing
   - Web API endpoint
   - Database indexing

---

**Created**: 2026-02-13  
**Status**: Ready for testing âœ…
